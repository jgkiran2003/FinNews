{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"./sentiment_analysis_model\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b5d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "    The company reported its quarterly earnings today, significantly exceeding analyst expectations.\n",
    "    Revenue growth was strong across all major divisions, climbing 15% year-over-year to a record $2.5 billion.\n",
    "    This impressive performance was driven by robust demand for its new product line and successful expansion into international markets.\n",
    "    Citing these positive trends, the management team has upwardly revised its forecast for the full fiscal year and remains confident in its ability to deliver strong shareholder value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b17e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text: '\n",
      "    The company reported its quarterly earnings today, significantly exceeding analyst expectations.\n",
      "    Revenue growth was strong across all major divisions, climbing 15% year-over-year to a record $2.5 billion.\n",
      "    This impressive performance was driven by robust demand for its new product line and successful expansion into international markets.\n",
      "    Citing these positive trends, the management team has upwardly revised its forecast for the full fiscal year and remains confident in its ability to deliver strong shareholder value.\n",
      "'\n",
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Prepare the text for the model (Tokenize) ---\n",
    "#    'return_tensors=\"pt\"' tells the tokenizer to return PyTorch tensors.\n",
    "inputs = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# --- 4. Make a prediction ---\n",
    "#    'with torch.no_grad()' is a good practice for inference as it disables\n",
    "#    gradient calculations, making it faster and using less memory.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# --- 5. Convert the output to a prediction ---\n",
    "#    Get the class with the highest probability\n",
    "predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "#    Use the model's config to get the human-readable label\n",
    "predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(f\"Sample Text: '{sample_text}'\")\n",
    "print(f\"Predicted Sentiment: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance_app_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
